{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91da46a4",
   "metadata": {
    "papermill": {
     "duration": 0.006362,
     "end_time": "2023-08-04T15:20:37.257870",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.251508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><b> In this notebook, I have tried my best to the UNet architecture with the help of illustrations and in-depth descriptions along with its implementation from scratch. Feedback would be greatly appreciated :)</b></center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c86f7",
   "metadata": {
    "papermill": {
     "duration": 0.005204,
     "end_time": "2023-08-04T15:20:37.268973",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.263769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Learnings Objectives of this Notebook\n",
    "\n",
    "* What is UNet Architecture?\n",
    "* Working and Breakdown of UNet Architecture.\n",
    "* Practicle Implementation of UNet.\n",
    "* Applications of UNet Architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a228c82",
   "metadata": {
    "papermill": {
     "duration": 0.005426,
     "end_time": "2023-08-04T15:20:37.280483",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.275057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is a one stop destination to learn everything about **UNet Architecture**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c8c15",
   "metadata": {
    "papermill": {
     "duration": 0.00535,
     "end_time": "2023-08-04T15:20:37.291385",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.286035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is UNet Architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cb119",
   "metadata": {
    "papermill": {
     "duration": 0.005328,
     "end_time": "2023-08-04T15:20:37.302302",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.296974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The U-Net is a convolutional neural network initially developed for biomedical image segmentation at the University of Freiburg, Germany. It is an extension of the fully convolutional network proposed by Long, Shelhamer, and Darrell.\n",
    "\n",
    "The **U-Net architecture** enhances the segmentation accuracy by incorporating upsampling operators instead of pooling operations, which increases the output resolution. Additionally, the network employs a **symmetric u-shaped structure**. This design choice enables the network to capture and propagate context information effectively. By utilizing a large number of feature channels in the upsampling part, the network can extract and utilize rich contextual information, leading to more accurate segmentations.\n",
    "\n",
    "Unlike traditional networks that rely on fully connected layers, the U-Net does not use them and instead extrapolates missing context in the border region by **mirroring the input image**. This approach enables the network to handle large images efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832eabd",
   "metadata": {
    "papermill": {
     "duration": 0.005157,
     "end_time": "2023-08-04T15:20:37.313004",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.307847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![UNet](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8a8eb",
   "metadata": {
    "papermill": {
     "duration": 0.006736,
     "end_time": "2023-08-04T15:20:37.325239",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.318503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "# Breakdown of UNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16758aac",
   "metadata": {
    "papermill": {
     "duration": 0.005292,
     "end_time": "2023-08-04T15:20:37.335982",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.330690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The U-Net architecture consists of an encoder-decoder structure with skip connections, enabling it to capture both high-level and low-level features. \n",
    "\n",
    "Here's a breakdown of the U-Net architecture:\n",
    "\n",
    "1. **Encoder:** The encoder is responsible for capturing high-level features from the input image.\n",
    "   - It starts with a series of convolutional layers with a **ReLU activation** function, followed by **padding** to maintain spatial dimensions.\n",
    "   - **Convolutional layers** apply a set of filters to extract features.\n",
    "   - After each convolutional layer, another convolutional layer with the same number of filters is applied to capture more complex features.\n",
    "   - **MaxPooling** is performed to downsample the feature maps and reduce spatial dimensions.\n",
    "   <br><br><br>\n",
    "\n",
    "2. **Bridge:** The bridge connects the encoder and decoder through skip connections.\n",
    "   - It consists of additional convolutional layers with **ReLU activation**.\n",
    "   - The bridge helps in preserving spatial information by concatenating the feature maps from the encoder to the corresponding decoder layers.\n",
    "<br><br><br>\n",
    "3. **Decoder:** The decoder generates the final segmentation map using the concatenated feature maps from the bridge.\n",
    "   - It starts with **upsampling** to increase the spatial dimensions of the feature maps.\n",
    "   - **Convolutional layers** with **ReLU activation** are applied to refine the feature maps.\n",
    "   - The **upsampled feature maps** are concatenated with the corresponding feature maps from the encoder.\n",
    "   - More convolutional layers are applied to further refine the features.\n",
    "   - The decoder ends with a **convolutional layer with a sigmoid activation** function to produce the final segmentation map.\n",
    "\n",
    "The U-Net architecture leverages skip connections to combine both high-level and low-level features, allowing it to capture fine-grained details while maintaining contextual information. This makes it effective for tasks such as image segmentation, where precise delineation of object boundaries is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594ab6a",
   "metadata": {
    "papermill": {
     "duration": 0.005284,
     "end_time": "2023-08-04T15:20:37.346763",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.341479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's go through the basics of convolution & deconvolution<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff373ad",
   "metadata": {
    "papermill": {
     "duration": 0.00518,
     "end_time": "2023-08-04T15:20:37.357406",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.352226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Understanding Convolution Operation\n",
    "Convolution operation is an essential technique used in convolutional neural networks (CNNs) for image classification. It involves using a feature detector/kernel/filter of a certain size (e.g., 3x3, 5x5, or 7x7) to detect specific features in an image, such as edges or shapes. The feature detector convolves or slides over the input image, performing element-wise multiplication of the corresponding pixel values. This results in a feature map or convolved feature that highlights the detected feature in the image. We use multiple feature detectors to create multiple feature maps, which are important for accurate classification. The stride is the number of steps that the feature detector takes while navigating over the input image. The size of the input image is reduced during convolution, which is useful for faster processing, but it also results in some loss of information.\n",
    "\n",
    " <a href=\"https://imgbb.com/\"><img src=\"https://image.ibb.co/m4FQC9/gec.jpg\" alt=\"gec\" border=\"0\"></a><br>\n",
    " After applying the convolutional layer, ReLU activation function is used to introduce non-linearity in the model. This helps in breaking the linearity of the image data and improving the model's ability to capture non-linear features in the image (as most of the data is non-linear in nature, we need to introduce back non-linearity)\n",
    " <br>\n",
    " <a href=\"https://ibb.co/mVZih9\"><img src=\"https://preview.ibb.co/gbcQvU/RELU.jpg\" alt=\"RELU\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e6f2f",
   "metadata": {
    "papermill": {
     "duration": 0.005192,
     "end_time": "2023-08-04T15:20:37.368017",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.362825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "# Understanding Deconvolution Operation\n",
    "The deconvolution operation is used to increase the spatial dimensions of feature maps. It is the inverse operation of convolution and is often employed in the decoder part of architectures like U-Net for upsampling.\n",
    "\n",
    "Here's a breakdown of the deconvolution operation:\n",
    "\n",
    "1. **Upsampling:** The deconvolution operation starts with **upsampling** the input feature map to increase its spatial dimensions. This is typically done by inserting empty rows and columns between the existing elements. \n",
    "\n",
    "2. **Convolution:** After upsampling, a **convolutional layer** is applied to the upsampled feature map. The convolutional layer applies a set of learnable filters to the feature map, enabling it to learn patterns and extract features.\n",
    "\n",
    "3. **Stride:** The deconvolution operation involves using a **stride value greater than 1** during the convolution step. The stride determines the step size used when sliding the filters over the input. A stride greater than 1 increases the spatial dimensions of the output feature map.\n",
    "\n",
    "4. **Padding:** To ensure that the output feature map has the desired spatial dimensions, **padding** can be applied before the convolution step. Padding inserts additional rows and columns of zeros around the input feature map, preserving its size during the convolution operation.\n",
    "\n",
    "5. **Activation:** Finally, an **activation function** is typically applied to introduce non-linearity and make the deconvolution operation capable of modeling complex relationships between features.\n",
    "\n",
    "The deconvolution operation is commonly used in tasks such as image upsampling, where low-resolution images need to be enlarged to match higher resolutions. It is also used in image generation tasks, such as in Generative Adversarial Networks (GANs), to produce realistic and high-resolution images.\n",
    "\n",
    "To visualize deconvolution operation, you can refer to the above gif \n",
    "![https://miro.medium.com/v2/resize:fit:790/1*8MhRh4T970Ewp4EYHq4aEQ.gif](https://miro.medium.com/v2/resize:fit:790/1*8MhRh4T970Ewp4EYHq4aEQ.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a2918",
   "metadata": {
    "papermill": {
     "duration": 0.005784,
     "end_time": "2023-08-04T15:20:37.380653",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.374869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6a464",
   "metadata": {
    "papermill": {
     "duration": 0.005261,
     "end_time": "2023-08-04T15:20:37.391439",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.386178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# implementing UNET From Scratch\n",
    "In the original paper, the UNET is described as follows:\n",
    "\n",
    "![](https://miro.medium.com/max/875/1*OkUrpDD6I0FpugA_bbYBJQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cde836",
   "metadata": {
    "papermill": {
     "duration": 0.005085,
     "end_time": "2023-08-04T15:20:37.401947",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.396862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From the above figure, we can interpret-\n",
    "- The U-Net architecture consists of two consecutive convolutional layers in each block\n",
    "\n",
    "\n",
    "\n",
    "- The left-hand side of the U-Net architecture corresponds to the **contraction path (Encoder)**. This path involves applying regular convolutions and max pooling layers.\n",
    "\n",
    "- In the Encoder, the input image gradually reduces in size while the depth (number of channels) increases. For example, the image may go from 572x572x3 to 284x284x128\n",
    "\n",
    "- The Encoder learns the \"WHAT\" information in the image, but it loses the \"WHERE\" information, which refers to precise localization.\n",
    "\n",
    "- The right-hand side of the U-Net architecture represents the **expansion path (Decoder)**. This path applies transposed convolutions along with regular convolutions.\n",
    "\n",
    "- In the Decoder, the size of the image gradually increases, while the depth decreases. For instance, the image may go from 8x8x256 to 128x128x1.\n",
    "\n",
    "- The Decoder recovers the \"WHERE\" information by gradually applying up-sampling to obtain precise localization.\n",
    "\n",
    "- To achieve more accurate localization, **skip connections** are employed. These connections involve concatenating the output of transposed convolutional layers with the corresponding feature maps from the Encoder:\n",
    "  - u6 = u6 + c4\n",
    "  - u7 = u7 + c3\n",
    "  - u8 = u8 + c2\n",
    "  - u9 = u9 + c1\n",
    "\n",
    "  After concatenation, two consecutive regular convolutions are applied to refine the output.\n",
    "\n",
    "- The U-Net architecture's symmetric U-shape, along with skip connections, contributes to its name: **UNET**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ea714",
   "metadata": {
    "papermill": {
     "duration": 0.005143,
     "end_time": "2023-08-04T15:20:37.412420",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.407277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we implement the UNET architecture **as per the paper** (done in pytorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519bafa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T15:20:37.425325Z",
     "iopub.status.busy": "2023-08-04T15:20:37.424905Z",
     "iopub.status.idle": "2023-08-04T15:20:41.323478Z",
     "shell.execute_reply": "2023-08-04T15:20:41.322189Z"
    },
    "papermill": {
     "duration": 3.908559,
     "end_time": "2023-08-04T15:20:41.326347",
     "exception": false,
     "start_time": "2023-08-04T15:20:37.417788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, inp, out,paddi=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inp, out, kernel_size=3,padding=paddi)\n",
    "        self.conv2 = nn.Conv2d(out, out, kernel_size=3,padding=paddi)\n",
    "       \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "    \n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "    \n",
    "        x = self.relu(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class downsample_block(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(inp, out)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        \n",
    "        return x, p\n",
    "\n",
    "\n",
    "\n",
    "class upsample_block(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(inp, out, kernel_size=2, stride=2)\n",
    "        self.conv = conv_block(out+out, out)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "       \n",
    "        self.d1 = downsample_block(1, 64)\n",
    "        self.d2 = downsample_block(64, 128)\n",
    "        self.d3 = downsample_block(128, 256)\n",
    "        self.d4 = downsample_block(256, 512)\n",
    "\n",
    "     \n",
    "        self.b = conv_block(512, 1024,1)\n",
    "\n",
    "       \n",
    "        self.u1 = upsample_block(1024, 512)\n",
    "        self.u2 = upsample_block(512, 256)\n",
    "        self.u3 = upsample_block(256, 128)\n",
    "        self.u4 = upsample_block(128, 64)\n",
    "\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "     \n",
    "        s1, p1 = self.d1(inputs)\n",
    "        s2, p2 = self.d2(p1)\n",
    "        s3, p3 = self.d3(p2)\n",
    "        s4, p4 = self.d4(p3)\n",
    "\n",
    "     \n",
    "        b = self.b(p4)\n",
    "\n",
    "        u1 = self.u1(b, s4)\n",
    "        u2 = self.u2(u1, s3)\n",
    "        u3 = self.u3(u2, s2)\n",
    "        u4 = self.u4(u3, s1)\n",
    "\n",
    "    \n",
    "        outputs = self.outputs(u4)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d3c64",
   "metadata": {
    "papermill": {
     "duration": 0.005374,
     "end_time": "2023-08-04T15:20:41.337421",
     "exception": false,
     "start_time": "2023-08-04T15:20:41.332047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "# Applications of UNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453dc883",
   "metadata": {
    "papermill": {
     "duration": 0.00547,
     "end_time": "2023-08-04T15:20:41.348439",
     "exception": false,
     "start_time": "2023-08-04T15:20:41.342969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **Medical Image Segmentation:** UNet is extensively used for segmenting organs, tumors, and structures in medical images like MRI scans and CT scans, providing precise and detailed segmentation results.<br><br>\n",
    "- **Object Detection and Instance Segmentation:** UNet can be adapted to handle object detection and instance segmentation tasks in computer vision, enabling accurate detection and localization of objects in images and videos.<br><br>\n",
    "- **Satellite Image Analysis:** UNet finds applications in satellite image analysis, such as land cover classification, building detection, and road extraction, contributing to remote sensing and geospatial analysis.<br><br>\n",
    "- **Autonomous Driving:** UNet-based models are employed in autonomous driving systems for tasks like semantic segmentation, enabling vehicles to perceive and understand the environment accurately, enhancing safety and decision-making.<br><br>\n",
    "- **Robotics:** UNet is utilized in robotics for tasks like scene understanding, object recognition, and manipulation, allowing robots to perceive and interact with their surroundings effectively.<br><br>\n",
    "- **Biomedical Research:** UNet plays a vital role in biomedical research, assisting in cell and tissue segmentation, disease detection, and analysis of microscopic images.<br><br>\n",
    "- **Natural Language Processing:** UNet has even found applications in natural language processing, specifically in text segmentation tasks, such as segmenting paragraphs, sentences, or words from textual data.<br><br>\n",
    "- **Image Restoration and Denoising:** UNet can be employed for image restoration tasks, such as denoising, inpainting, and super-resolution, by effectively capturing and restoring missing or corrupted information in images.<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0945ea8",
   "metadata": {
    "papermill": {
     "duration": 0.005316,
     "end_time": "2023-08-04T15:20:41.359297",
     "exception": false,
     "start_time": "2023-08-04T15:20:41.353981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Further Reading\n",
    "For a complete in-depth introduction to CNNs, you may also refer to the below notebook-\n",
    "https://www.kaggle.com/code/akshitsharma1/a-fascinating-introduction-to-cnns-tutorial/\n",
    "\n",
    "**Original Paper Link** https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fb846",
   "metadata": {
    "papermill": {
     "duration": 0.005193,
     "end_time": "2023-08-04T15:20:41.369985",
     "exception": false,
     "start_time": "2023-08-04T15:20:41.364792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.290015,
   "end_time": "2023-08-04T15:20:43.627054",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-04T15:20:23.337039",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
